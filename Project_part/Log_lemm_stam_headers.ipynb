{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала мутим словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open(\"data/docs_titles/lemm_titles.csv\") as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split(',', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title=data[1]\n",
    "#             title = regex.sub(r'[^\\p{Cyrillic}]+', ' ', data[1]).lower()\n",
    "            title = ' '.join(word for word in title.split() if len(word)>2)\n",
    "        doc_to_title[doc_id] = title\n",
    "print (len(doc_to_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_to_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция делает словарь {группа: [ (тайтл, таргет) ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_groups.csv')\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Минимальная длина пересечений 25, значит фич не больше 25 может быть получается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrain(params):\n",
    "    y_train = []\n",
    "    X_train = []\n",
    "    for new_group in tqdm(traingroups_titledata):\n",
    "        docs = traingroups_titledata[new_group]\n",
    "        ln = 0\n",
    "        for j in range(0, len(docs)):\n",
    "            doc_id_j, title_j, target_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            ln += len(words_j)\n",
    "        ln /= len(docs)\n",
    "        for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "            y_train.append(target_id)\n",
    "            all_dist = []  \n",
    "            words = set(title.strip().split())\n",
    "            for j in range(0, len(docs)):\n",
    "                if k == j:\n",
    "                    continue\n",
    "                doc_id_j, title_j, target_j = docs[j]\n",
    "                words_j = set(title_j.strip().split())\n",
    "                all_dist.append(len(words.intersection(words_j)))\n",
    "            all_dist.sort(reverse=True)\n",
    "            all_dist = all_dist[0:params]\n",
    "            all_dist.append(abs(len(words) - ln))\n",
    "#             print(abs(len(words) - ln))\n",
    "            X_train.append(all_dist)\n",
    "#             X_train.append(abs(len(words) - ln))            \n",
    "            \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe1dba164324630b6bd8bdcf46f8e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=129.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 1.08776295  0.92357     1.09527046 ...  0.96980722  1.02092127\n",
      "  -0.61365744]\n",
      " [ 1.56706747  1.99577152  2.22111893 ...  0.96980722  1.02092127\n",
      "  -0.14775971]\n",
      " [ 0.12915391  0.38746923  0.53234623 ...  0.33577968  0.37654085\n",
      "   0.27654002]\n",
      " ...\n",
      " [-1.30875964 -1.22083306 -1.15642647 ... -0.93227539 -0.91221997\n",
      "   1.02973831]\n",
      " [ 1.08776295 -0.68473229 -0.59350224 ... -0.29824785 -0.26783956\n",
      "   0.33034316]\n",
      " [-0.82945512 -0.68473229 -0.59350224 ... -0.93227539 -0.91221997\n",
      "   1.17894261]]\n"
     ]
    }
   ],
   "source": [
    "a, b = getTrain(10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = 6\n",
    "kf = KFold(n_splits=splits)\n",
    "\n",
    "def max_barrier(clf, X, y):\n",
    "    \"\"\"\n",
    "    Подбираем порог линейной модели, \n",
    "    по достижению которого относим объект \n",
    "    к классу 1\n",
    "    \"\"\"\n",
    "    (max_score, max_barr) = (0, 0)\n",
    "    for barr in np.arange (0, 1, 0.01):\n",
    "            probe = list(zip(*clf.predict_proba(X)))[1]\n",
    "            score = f1_score(y, probe > barr)\n",
    "#             print(barr, score)\n",
    "            if score > max_score:\n",
    "#                 print(\"AAaaaaaaaaaaaaaaaaa\")\n",
    "#                 print(barr, score)\n",
    "                max_score, max_barr = score, barr\n",
    "    return max_score, max_barr\n",
    "\n",
    "def get_best(penalty_list, c_list, l1_ratio_list, fiches_list):\n",
    "    \"\"\"\n",
    "    Делаем кросс валидацию и, таким образом, \n",
    "    подбираем оптимальные параметры.\n",
    "    \"\"\"\n",
    "    max_result = -1\n",
    "    for i, (penalty, C, l1_ratio, fiches) in tqdm(list(enumerate(product(penalty_list, c_list, l1_ratio_list, fiches_list)))):\n",
    "        result = 0.0\n",
    "        X_tran, y_tran = getTrain(fiches)\n",
    "        for train_index, test_index in kf.split(X_tran):\n",
    "            X_tr, X_tst = X_tran[train_index], X_tran[test_index]\n",
    "            y_tr, y_tst = y_tran[train_index], y_tran[test_index]\n",
    "            \n",
    "            clf = LogisticRegression(C=C, penalty=penalty, class_weight='balanced', solver='saga', l1_ratio=l1_ratio, max_iter = 1000)\n",
    "            clf.fit(X_tr, y_tr)\n",
    "            \n",
    "            score, barrier = max_barrier(clf, X_tst, y_tst)\n",
    "#             print(clf.predict(X_tst))\n",
    "#             print(penalty, C, l1_ratio, barrier)\n",
    "#             probe = clf.predict_proba(X_tst))\n",
    "            result += score\n",
    "        \n",
    "        result /= splits\n",
    "        print(result, fiches)\n",
    "        if result > max_result:\n",
    "            max_result = result\n",
    "            params = {'C': C, 'penalty': penalty, 'l1_ratio': l1_ratio, 'barrier':barrier, 'fiches': fiches}\n",
    "            print(params)\n",
    "    \n",
    "    print('max_f1_score =', max_result, 'with', params)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0.95, 0.5, 0.1]\n",
      "[21]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e843b63efb3424aa9b43c4769d2db91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7689fa21390f488bb8aa182ac6d8bcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=129.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6935027730909339 21\n",
      "{'C': 1, 'penalty': 'elasticnet', 'l1_ratio': 0.95, 'barrier': 0.55, 'fiches': 21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405a5d39371d477ab1eeed533a0054ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=129.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.69268042308667 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ccab3abe194f6ca018a62101c98fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=129.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6926202259376347 21\n",
      "\n",
      "max_f1_score = 0.6935027730909339 with {'C': 1, 'penalty': 'elasticnet', 'l1_ratio': 0.95, 'barrier': 0.55, 'fiches': 21}\n"
     ]
    }
   ],
   "source": [
    "l1_ratio_list = [0.95]#np.arange(0.1, 1.1, 0.01)\n",
    "c_list = [1]#np.logspace(10, 1, )\n",
    "fiches_list = [21]#np.arange(3, 25, 1)\n",
    "\n",
    "penalty_list = ['elasticnet']\n",
    "\n",
    "print(c_list)\n",
    "print(l1_ratio_list)\n",
    "print(fiches_list)\n",
    "\n",
    "log_params = get_best(penalty_list, c_list, l1_ratio_list, fiches_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9b9847cd1648558368177e6b4e7592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=129.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = getTrain(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тест надо чуть поменять еще одна фича же"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16627, 22)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/test_groups.csv')\n",
    "testgroups_titledata = {}\n",
    "for i in range(len(test_data)):\n",
    "    new_doc = test_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    pair_id = new_doc['pair_id']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in testgroups_titledata:\n",
    "        testgroups_titledata[doc_group] = []\n",
    "    testgroups_titledata[doc_group].append((doc_id, pair_id, title))\n",
    "    \n",
    "X_test = []\n",
    "pairs_id = []\n",
    "for new_group in testgroups_titledata:\n",
    "    docs = testgroups_titledata[new_group]        \n",
    "    ln = 0\n",
    "    for j in range(0, len(docs)):\n",
    "        *_, title_j = docs[j]\n",
    "        words_j = set(title_j.strip().split())\n",
    "        ln += len(words_j)\n",
    "    ln /= len(docs)\n",
    "    for k, (doc_id, pair_id, title) in enumerate(docs):\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            *_, title_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            all_dist.append(len(words.intersection(words_j)))\n",
    "        \n",
    "        all_dist.sort(reverse=True)\n",
    "        all_dist = all_dist[0:log_params['fiches']]\n",
    "        all_dist.append(abs(len(words) - ln))\n",
    "        X_test.append(all_dist)\n",
    "        pairs_id.append(pair_id)\n",
    "X_test = np.array(X_test)\n",
    "# X_test = scaler.transform(X_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1,\n",
       " 'penalty': 'elasticnet',\n",
       " 'l1_ratio': 0.95,\n",
       " 'barrier': 0.55,\n",
       " 'fiches': 21}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=0.95, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='elasticnet',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(C=1, penalty='elasticnet', class_weight='balanced', solver='saga', l1_ratio=0.95, max_iter = 1000)\n",
    "log_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627, 22)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = scaler.fit_transform(X_test)\n",
    "probes = list(zip(*log_clf.predict_proba(X_test)))[1]\n",
    "predict = np.asarray(probes > log_params['barrier'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "test_data[\"target\"] = pd.Series(predict)\n",
    "with open(\"predict_stam_1.csv\", \"w\") as f:\n",
    "    f.write(test_data.to_csv(columns=(\"pair_id\", \"target\"), index=False))\n",
    "print(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
